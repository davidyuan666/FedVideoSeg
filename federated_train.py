"""
FedVideoQA è”é‚¦å­¦ä¹ è®­ç»ƒè„šæœ¬
åŸºäºç°æœ‰çš„ train_qwen.py å®ç°è”é‚¦å­¦ä¹ åŠŸèƒ½
å¢åŠ éšç§ä¿æŠ¤ï¼šå·®åˆ†éšç§ + å®‰å…¨èšåˆ
"""

import argparse
import logging
import json
import torch
import copy
import hashlib
import random
from typing import List, Dict, Any
from train_qwen import UnifiedTrainer, VideoQADataset
import os
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PrivacyEngine:
    """éšç§ä¿æŠ¤å¼•æ“"""
    
    def __init__(self, noise_multiplier: float = 1.0, max_grad_norm: float = 1.0):
        self.noise_multiplier = noise_multiplier
        self.max_grad_norm = max_grad_norm
        
    def add_differential_privacy_noise(self, weights: Dict[str, torch.Tensor], 
                                     sensitivity: float = 1.0) -> Dict[str, torch.Tensor]:
        """æ·»åŠ å·®åˆ†éšç§å™ªå£°"""
        noisy_weights = {}
        
        for key, weight in weights.items():
            if weight.requires_grad:
                # è®¡ç®—å™ªå£°æ ‡å‡†å·®
                noise_std = self.noise_multiplier * sensitivity
                
                # ç”Ÿæˆé«˜æ–¯å™ªå£°
                noise = torch.normal(0, noise_std, size=weight.shape, 
                                   dtype=weight.dtype, device=weight.device)
                
                # æ·»åŠ å™ªå£°
                noisy_weights[key] = weight + noise
            else:
                noisy_weights[key] = weight
                
        return noisy_weights
    
    def clip_gradients(self, model: torch.nn.Module):
        """æ¢¯åº¦è£å‰ª"""
        torch.nn.utils.clip_grad_norm_(model.parameters(), self.max_grad_norm)
    
    def encrypt_weights(self, weights: Dict[str, torch.Tensor], 
                       client_id: int) -> Dict[str, torch.Tensor]:
        """ç®€å•çš„æƒé‡åŠ å¯†/æ··æ·†"""
        encrypted_weights = {}
        
        # ä½¿ç”¨å®¢æˆ·ç«¯IDç”Ÿæˆéšæœºç§å­
        random.seed(client_id * 42)
        
        for key, weight in weights.items():
            # ç”Ÿæˆéšæœºæ©ç 
            mask = torch.rand_like(weight) * 0.1  # å°å¹…åº¦çš„éšæœºæ©ç 
            encrypted_weights[key] = weight + mask
            
        # é‡ç½®éšæœºç§å­
        random.seed()
        
        return encrypted_weights
    
    def decrypt_weights(self, encrypted_weights: Dict[str, torch.Tensor], 
                       client_id: int) -> Dict[str, torch.Tensor]:
        """è§£å¯†æƒé‡"""
        decrypted_weights = {}
        
        # ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­
        random.seed(client_id * 42)
        
        for key, weight in encrypted_weights.items():
            # ç”Ÿæˆç›¸åŒçš„éšæœºæ©ç 
            mask = torch.rand_like(weight) * 0.1
            decrypted_weights[key] = weight - mask
            
        # é‡ç½®éšæœºç§å­
        random.seed()
        
        return decrypted_weights

class PrivateFederatedClient:
    """æ”¯æŒéšç§ä¿æŠ¤çš„è”é‚¦å­¦ä¹ å®¢æˆ·ç«¯"""
    
    def __init__(self, client_id: int, args, data_subset: List, privacy_engine: PrivacyEngine):
        self.client_id = client_id
        self.args = args
        self.data = data_subset
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºtrainerï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹
        self.trainer = None
        self.privacy_engine = privacy_engine
        
        logger.info(f"éšç§ä¿æŠ¤å®¢æˆ·ç«¯ {client_id} åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®é‡: {len(data_subset)}")
    
    def _get_trainer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–trainer"""
        if self.trainer is None:
            # ä¿®æ”¹argsä»¥é¿å…device_mapå†²çª
            client_args = copy.deepcopy(self.args)
            # åœ¨federated learningä¸­ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç®¡ç†è®¾å¤‡åˆ†é…
            self.trainer = UnifiedTrainer(client_args)
        return self.trainer
    
    def local_train(self, global_weights: Dict[str, torch.Tensor], epochs: int = 1):
        """æœ¬åœ°è®­ç»ƒï¼ˆå«éšç§ä¿æŠ¤ï¼‰"""
        logger.info(f"å®¢æˆ·ç«¯ {self.client_id} å¼€å§‹éšç§ä¿æŠ¤æœ¬åœ°è®­ç»ƒ...")
        
        # è·å–trainerå®ä¾‹
        trainer = self._get_trainer()
        
        # åŠ è½½å…¨å±€æƒé‡
        try:
            trainer.model.load_state_dict(global_weights, strict=False)
        except Exception as e:
            logger.warning(f"åŠ è½½æƒé‡æ—¶å‡ºç°è­¦å‘Š: {e}")
            # å°è¯•æ›´å®½æ¾çš„åŠ è½½
            missing_keys, unexpected_keys = trainer.model.load_state_dict(global_weights, strict=False)
            if missing_keys:
                logger.info(f"ç¼ºå¤±çš„é”®: {missing_keys}")
            if unexpected_keys:
                logger.info(f"æ„å¤–çš„é”®: {unexpected_keys}")
        
        # åˆ›å»ºæœ¬åœ°æ•°æ®é›†
        dataset = VideoQADataset(
            self.data, 
            trainer.processor, 
            trainer.tokenizer,
            training_mode=self.args.training_mode
        )
        
        from torch.utils.data import DataLoader
        dataloader = DataLoader(
            dataset, 
            batch_size=self.args.batch_size, 
            shuffle=True,
            collate_fn=trainer.collate_fn
        )
        
        # æœ¬åœ°ä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(
            trainer.model.parameters(), 
            lr=self.args.learning_rate
        )
        
        # è®­ç»ƒ
        trainer.model.train()
        total_loss = 0
        
        for epoch in range(epochs):
            for batch in dataloader:
                batch = {k: v.to(trainer.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                optimizer.zero_grad()
                outputs = trainer.model(**batch)
                loss = outputs['loss']
                loss.backward()
                
                # æ¢¯åº¦è£å‰ªï¼ˆéšç§ä¿æŠ¤ï¼‰
                if self.args.use_privacy:
                    self.privacy_engine.clip_gradients(trainer.model)
                
                optimizer.step()
                total_loss += loss.item()
        
        avg_loss = total_loss / (epochs * len(dataloader))
        
        # è·å–è®­ç»ƒåçš„æƒé‡
        trained_weights = trainer.model.state_dict()
        
        # åº”ç”¨éšç§ä¿æŠ¤
        if self.args.use_privacy:
            # æ·»åŠ å·®åˆ†éšç§å™ªå£°
            trained_weights = self.privacy_engine.add_differential_privacy_noise(
                trained_weights, sensitivity=self.args.dp_sensitivity
            )
            
            # ç®€å•åŠ å¯†
            if self.args.use_encryption:
                trained_weights = self.privacy_engine.encrypt_weights(
                    trained_weights, self.client_id
                )
        
        logger.info(f"å®¢æˆ·ç«¯ {self.client_id} éšç§ä¿æŠ¤æœ¬åœ°è®­ç»ƒå®Œæˆï¼Œå¹³å‡æŸå¤±: {avg_loss:.4f}")
        
        return trained_weights, len(self.data)

class PrivateFederatedServer:
    """æ”¯æŒéšç§ä¿æŠ¤çš„è”é‚¦å­¦ä¹ æœåŠ¡å™¨"""
    
    def __init__(self, args, privacy_engine: PrivacyEngine):
        self.args = args
        # åªåœ¨æœåŠ¡å™¨ç«¯åˆ›å»ºä¸€ä¸ªå…¨å±€æ¨¡å‹å®ä¾‹
        try:
            trainer = UnifiedTrainer(args)
            self.global_model = trainer.model
            self.device = trainer.device
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å…¨å±€æ¨¡å‹å¤±è´¥: {e}")
            # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ç®€å•çš„æ¨¡å‹åˆå§‹åŒ–
            if args.training_mode == "encoder":
                from train_qwen import QwenEncoderClassifier
                self.global_model = QwenEncoderClassifier(args.model_name, freeze_backbone=args.freeze_backbone)
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                self.global_model.to(self.device)
            else:
                raise e
        
        self.clients = []
        self.privacy_engine = privacy_engine
        
    def add_client(self, client: PrivateFederatedClient):
        """æ·»åŠ å®¢æˆ·ç«¯"""
        self.clients.append(client)
    
    def secure_federated_averaging(self, client_weights: List[Dict], 
                                 client_sizes: List[int]) -> Dict[str, torch.Tensor]:
        """å®‰å…¨è”é‚¦å¹³å‡ç®—æ³•"""
        logger.info("æ‰§è¡Œå®‰å…¨è”é‚¦å¹³å‡...")
        
        # å¦‚æœå¯ç”¨äº†åŠ å¯†ï¼Œå…ˆè§£å¯†
        if self.args.use_encryption:
            decrypted_weights = []
            for i, weights in enumerate(client_weights):
                decrypted = self.privacy_engine.decrypt_weights(weights, i)
                decrypted_weights.append(decrypted)
            client_weights = decrypted_weights
        
        # è®¡ç®—æƒé‡
        total_size = sum(client_sizes)
        weights = [size / total_size for size in client_sizes]
        
        # åˆå§‹åŒ–å¹³å‡æƒé‡
        avg_weights = copy.deepcopy(client_weights[0])
        for key in avg_weights.keys():
            avg_weights[key] = avg_weights[key] * weights[0]
        
        # åŠ æƒå¹³å‡
        for i in range(1, len(client_weights)):
            for key in avg_weights.keys():
                if key in client_weights[i]:
                    avg_weights[key] += client_weights[i][key] * weights[i]
        
        # å¯é€‰ï¼šåœ¨æœåŠ¡å™¨ç«¯ä¹Ÿæ·»åŠ ä¸€äº›å™ªå£°
        if self.args.use_privacy and self.args.server_noise:
            avg_weights = self.privacy_engine.add_differential_privacy_noise(
                avg_weights, sensitivity=self.args.dp_sensitivity * 0.5
            )
        
        return avg_weights
    
    def train_round(self, round_num: int, local_epochs: int = 1):
        """å•è½®è”é‚¦è®­ç»ƒ"""
        logger.info(f"å¼€å§‹ç¬¬ {round_num} è½®éšç§ä¿æŠ¤è”é‚¦è®­ç»ƒ...")
        
        # è·å–å½“å‰å…¨å±€æƒé‡
        global_weights = self.global_model.state_dict()
        
        # å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ
        client_weights = []
        client_sizes = []
        
        for client in self.clients:
            weights, size = client.local_train(global_weights, local_epochs)
            client_weights.append(weights)
            client_sizes.append(size)
        
        # å®‰å…¨è”é‚¦å¹³å‡
        new_global_weights = self.secure_federated_averaging(client_weights, client_sizes)
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(new_global_weights)
        
        logger.info(f"ç¬¬ {round_num} è½®éšç§ä¿æŠ¤è”é‚¦è®­ç»ƒå®Œæˆ")
    
    def save_global_model(self, round_num: int):
        """ä¿å­˜å…¨å±€æ¨¡å‹"""
        save_path = f"private_federated_model_round_{round_num}.pth"
        torch.save(self.global_model.state_dict(), save_path)
        logger.info(f"éšç§ä¿æŠ¤å…¨å±€æ¨¡å‹å·²ä¿å­˜åˆ° {save_path}")
    
    def privacy_audit(self, round_num: int):
        """éšç§å®¡è®¡æŠ¥å‘Š"""
        if self.args.use_privacy:
            epsilon = self.calculate_privacy_budget(round_num)
            logger.info(f"éšç§å®¡è®¡ - ç¬¬ {round_num} è½®:")
            logger.info(f"  ä¼°ç®—éšç§é¢„ç®— (Îµ): {epsilon:.4f}")
            logger.info(f"  å™ªå£°å€æ•°: {self.privacy_engine.noise_multiplier}")
            logger.info(f"  æ¢¯åº¦è£å‰ªèŒƒæ•°: {self.privacy_engine.max_grad_norm}")
    
    def calculate_privacy_budget(self, round_num: int) -> float:
        """è®¡ç®—éšç§é¢„ç®—ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # ç®€åŒ–çš„éšç§é¢„ç®—è®¡ç®—
        # å®é™…åº”ç”¨ä¸­éœ€è¦æ›´ç²¾ç¡®çš„è®¡ç®—
        base_epsilon = 1.0 / (self.privacy_engine.noise_multiplier ** 2)
        total_epsilon = base_epsilon * round_num
        return total_epsilon

def split_data_federated(data: List, num_clients: int, split_type: str = "iid"):
    """å°†æ•°æ®åˆ†å‰²ç»™å¤šä¸ªå®¢æˆ·ç«¯"""
    logger.info(f"å°†æ•°æ®åˆ†å‰²ç»™ {num_clients} ä¸ªå®¢æˆ·ç«¯ï¼Œåˆ†å‰²ç±»å‹: {split_type}")
    
    if split_type == "iid":
        # IIDåˆ†å‰²ï¼šéšæœºåˆ†é…
        np.random.shuffle(data)
        client_data = []
        chunk_size = len(data) // num_clients
        
        for i in range(num_clients):
            start = i * chunk_size
            end = start + chunk_size if i < num_clients - 1 else len(data)
            client_data.append(data[start:end])
    
    else:  # non-iid
        # Non-IIDåˆ†å‰²ï¼šæŒ‰æ ‡ç­¾åˆ†å¸ƒ
        # ç®€åŒ–å®ç°ï¼šè®©æ¯ä¸ªå®¢æˆ·ç«¯ä¸»è¦æ‹¥æœ‰æŸç§æ ‡ç­¾çš„æ•°æ®
        positive_data = [item for item in data if item[2] == 1]
        negative_data = [item for item in data if item[2] == 0]
        
        client_data = [[] for _ in range(num_clients)]
        
        # ä¸»è¦æ•°æ®åˆ†é…
        for i in range(num_clients):
            if i % 2 == 0:  # å¶æ•°å®¢æˆ·ç«¯ä¸»è¦åˆ†é…æ­£æ ·æœ¬
                main_data = positive_data[i//2 * len(positive_data)//((num_clients+1)//2):(i//2+1) * len(positive_data)//((num_clients+1)//2)]
                minor_data = negative_data[i//2 * len(negative_data)//(num_clients*2):(i//2+1) * len(negative_data)//(num_clients*2)]
            else:  # å¥‡æ•°å®¢æˆ·ç«¯ä¸»è¦åˆ†é…è´Ÿæ ·æœ¬
                main_data = negative_data[i//2 * len(negative_data)//(num_clients//2):(i//2+1) * len(negative_data)//(num_clients//2)]
                minor_data = positive_data[i//2 * len(positive_data)//(num_clients*2):(i//2+1) * len(positive_data)//(num_clients*2)]
            
            client_data[i] = main_data + minor_data
    
    # æ‰“å°åˆ†å‰²ç»Ÿè®¡
    for i, data_subset in enumerate(client_data):
        pos_count = sum(1 for item in data_subset if item[2] == 1)
        neg_count = len(data_subset) - pos_count
        logger.info(f"å®¢æˆ·ç«¯ {i}: æ€»æ•°æ® {len(data_subset)}, æ­£æ ·æœ¬ {pos_count}, è´Ÿæ ·æœ¬ {neg_count}")
    
    return client_data

def main():
    parser = argparse.ArgumentParser(description="FedVideoQA éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ è®­ç»ƒ")
    
        # åŸºç¡€å‚æ•°ï¼ˆå¤ç”¨train_qwen.pyçš„å‚æ•°ï¼‰
    parser.add_argument("--model_name", type=str, 
                       default="Qwen/Qwen2.5-VL-3B-Instruct",
                       help="Qwenæ¨¡å‹åç§°")
    parser.add_argument("--data_file", type=str, required=True,
                       help="è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--num_samples", type=int, default=100,
                       help="åˆæˆæ•°æ®æ ·æœ¬æ•°é‡")
    
    # è®­ç»ƒæ¨¡å¼
    parser.add_argument("--training_mode", type=str, 
                       choices=["encoder", "instruction"], 
                       default="encoder",
                       help="è®­ç»ƒæ¨¡å¼")
    parser.add_argument("--freeze_backbone", action="store_true",
                       help="å†»ç»“backbone")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--batch_size", type=int, default=2,
                       help="æ‰¹å¤§å°")
    parser.add_argument("--learning_rate", type=float, default=2e-5,
                       help="å­¦ä¹ ç‡")
    
    # LoRAå‚æ•°
    parser.add_argument("--use_lora", action="store_true",
                       help="ä½¿ç”¨LoRAå¾®è°ƒ")
    parser.add_argument("--lora_r", type=int, default=16,
                       help="LoRA rank")
    parser.add_argument("--lora_alpha", type=int, default=32,
                       help="LoRA alpha")
    parser.add_argument("--lora_targets", type=str, nargs="+", 
                       default=["q_proj", "v_proj", "k_proj", "o_proj"],
                       help="LoRAç›®æ ‡æ¨¡å—")
    parser.add_argument("--lora_dropout", type=float, default=0.1,
                       help="LoRA dropout")
    
    # è”é‚¦å­¦ä¹ å‚æ•°
    parser.add_argument("--num_clients", type=int, default=3,
                       help="å®¢æˆ·ç«¯æ•°é‡")
    parser.add_argument("--num_rounds", type=int, default=5,
                       help="è”é‚¦å­¦ä¹ è½®æ•°")
    parser.add_argument("--local_epochs", type=int, default=1,
                       help="æ¯è½®æœ¬åœ°è®­ç»ƒè½®æ•°")
    parser.add_argument("--split_type", type=str, 
                       choices=["iid", "non_iid"], 
                       default="iid",
                       help="æ•°æ®åˆ†å‰²ç±»å‹")
    
    # éšç§ä¿æŠ¤å‚æ•°
    parser.add_argument("--use_privacy", action="store_true",
                       help="å¯ç”¨éšç§ä¿æŠ¤")
    parser.add_argument("--noise_multiplier", type=float, default=1.0,
                       help="å·®åˆ†éšç§å™ªå£°å€æ•°")
    parser.add_argument("--max_grad_norm", type=float, default=1.0,
                       help="æ¢¯åº¦è£å‰ªæœ€å¤§èŒƒæ•°")
    parser.add_argument("--dp_sensitivity", type=float, default=1.0,
                       help="å·®åˆ†éšç§æ•æ„Ÿåº¦")
    parser.add_argument("--use_encryption", action="store_true",
                       help="å¯ç”¨ç®€å•åŠ å¯†")
    parser.add_argument("--server_noise", action="store_true",
                       help="åœ¨æœåŠ¡å™¨ç«¯ä¹Ÿæ·»åŠ å™ªå£°")
    
    args = parser.parse_args()
    
    logger.info("å¼€å§‹FedVideoQAéšç§ä¿æŠ¤è”é‚¦å­¦ä¹ è®­ç»ƒ...")
    logger.info(f"å®¢æˆ·ç«¯æ•°é‡: {args.num_clients}")
    logger.info(f"è”é‚¦å­¦ä¹ è½®æ•°: {args.num_rounds}")
    logger.info(f"æ•°æ®åˆ†å‰²ç±»å‹: {args.split_type}")
    logger.info(f"éšç§ä¿æŠ¤: {'å¯ç”¨' if args.use_privacy else 'ç¦ç”¨'}")
    if args.use_privacy:
        logger.info(f"  å™ªå£°å€æ•°: {args.noise_multiplier}")
        logger.info(f"  æ¢¯åº¦è£å‰ª: {args.max_grad_norm}")
        logger.info(f"  ç®€å•åŠ å¯†: {'å¯ç”¨' if args.use_encryption else 'ç¦ç”¨'}")
    
    # åŠ è½½æ•°æ®
    if not os.path.exists(args.data_file):
        logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data_file}")
        return
    
    trainer = UnifiedTrainer(args)
    data = trainer.load_data_from_file(args.data_file)
    
    # åˆ†å‰²æ•°æ®ç»™å®¢æˆ·ç«¯
    client_data_splits = split_data_federated(data, args.num_clients, args.split_type)
    
    # åˆå§‹åŒ–éšç§å¼•æ“
    privacy_engine = PrivacyEngine(
        noise_multiplier=args.noise_multiplier,
        max_grad_norm=args.max_grad_norm
    ) if args.use_privacy else None
    
    # åˆå§‹åŒ–æœåŠ¡å™¨
    server = PrivateFederatedServer(args, privacy_engine)
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    for i in range(args.num_clients):
        client = PrivateFederatedClient(i, args, client_data_splits[i], privacy_engine)
        server.add_client(client)
    
    # è”é‚¦å­¦ä¹ è®­ç»ƒ
    for round_num in range(1, args.num_rounds + 1):
        server.train_round(round_num, args.local_epochs)
        
        # éšç§å®¡è®¡
        if args.use_privacy:
            server.privacy_audit(round_num)
        
        # æ¯å‡ è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹
        if round_num % 2 == 0:
            server.save_global_model(round_num)
    
    # æœ€ç»ˆä¿å­˜
    server.save_global_model(args.num_rounds)
    
    # æœ€ç»ˆéšç§æŠ¥å‘Š
    if args.use_privacy:
        final_epsilon = server.calculate_privacy_budget(args.num_rounds)
        logger.info(f"ğŸ”’ æœ€ç»ˆéšç§é¢„ç®—: Îµ = {final_epsilon:.4f}")
        logger.info(f"ğŸ”’ éšç§ä¿æŠ¤çº§åˆ«: {'å¼º' if final_epsilon < 1.0 else 'ä¸­ç­‰' if final_epsilon < 10.0 else 'è¾ƒå¼±'}")
    
    logger.info("éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ è®­ç»ƒå®Œæˆï¼")

if __name__ == "__main__":
    main() 